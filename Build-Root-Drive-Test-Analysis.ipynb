{
 "metadata": {
  "name": "",
  "signature": "sha256:96251c7933e3ecd647af4e961da6b7ba5ea93054ca0904eedbd504a4fd5c8fdd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Single File Read Cell \n"
     ]
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": [
      "This Cell is meant just to read in a single File.  It will traverse the entire sub-directory, but really only returns the data for a single file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import re\n",
      "import csv\n",
      "import itertools\n",
      "import time\n",
      "import os\n",
      "import get_stats\n",
      "import get_root_dataframe\n",
      "import calc_distance as cd\n",
      "import pandas as pd\n",
      "\n",
      "%matplotlib inline\n",
      "# Valid values for type_flag = 'FAILED', 'ALL', 'CALL'\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline\n",
      "\n",
      "\n",
      "stat_list =[]\n",
      "#'city':;'mean':''max':''min':\n",
      "\n",
      "for path, subdirs, files in os.walk(\".\"):\n",
      "        for name in files:\n",
      "            if name.endswith(\".zip\"):\n",
      "                f = os.path.join(path,name)\n",
      "                # Careful @ this point the path is specific to the directory which will change\n",
      "                # depending on what system the data files are located.\n",
      "                head,filedate = os.path.split(path)\n",
      "                if True:\n",
      "                    _stat= {}\n",
      "                    pt_ct = 0\n",
      "                    # Get the basic file and base dataframe:\n",
      "                    \n",
      "                    df,filelist = get_root_dataframe.get_rm_df(f)\n",
      "                    #print filelist, '\\n',df['Collection'].head(5)\n",
      "                    \n",
      "                    \n",
      "                    \n",
      "                    # Get the CDMA status for failed calls:"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Read in the Metro to Vendor Mapping csv file"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Read csv mapping file into Pandas\n",
      "import os\n",
      "import pandas as pd\n",
      "import csv\n",
      "filename = 'RM_MSA_LookUP.csv'\n",
      "try:\n",
      "    with open(filename) as mapfile:\n",
      "        mapfile_df = pd.read_csv(mapfile,skipinitialspace=True,dtype=object)\n",
      "except:\n",
      "    print 'i/o error'\n",
      "# Now Get a separate test file    \n",
      "filename = 'test_file.csv'\n",
      "try:\n",
      "    with open(filename) as mapfile:\n",
      "        test_df = pd.read_csv(mapfile,skipinitialspace=True,dtype=object)\n",
      "except:\n",
      "    print 'i/o error'\n",
      "#test_df[['Sprint','Vendor']]= test_df[['Sprint','Vendor']].astype(str)\n",
      "mapfile_df= mapfile_df[['Sprint','Vendor']].astype(str)\n",
      "test_df2 = test_df[['Sprint']]\n",
      "mdf2 = mapfile_df.loc[mapfile_df['Vendor']=='STA']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Perform the merge with the Full Data Set"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# attempt to get the right type\n",
      "\n",
      "result =test_df.join(mapfile_df, on='Sprint',lsuffix ='_left',how='left')\n",
      "#result = pd.merge(mapfile_df,test_df, on='Sprint',suffixes=['_left','_right'], how='inner')\n",
      "merged_left = pd.merge(left=test_df,right=mapfile_df, how='left', left_on='Sprint', right_on='Sprint')\n",
      "merged_left.sort(columns='Vendor', ascending='True', inplace='True')\n",
      "print merged_left.head(5)\n",
      "print merged_left.tail(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                                        Sprint         Data Vendor\n",
        "123        Albany-NY_2015-1H_Sprint_Detail.csv  0.116642419    ALU\n",
        "1       Worcester-MA_2015-1H_Sprint_Detail.csv  0.193350028    ALU\n",
        "2    WinstonSalem-NC_2015-1H_Sprint_Detail.csv  0.498645411    ALU\n",
        "79       Hartford-CT_2015-1H_Sprint_Detail.csv  0.214585336    ALU\n",
        "4      Washington-DC_2015-1H_Sprint_Detail.csv  0.298136577    ALU\n",
        "                                      Sprint         Data Vendor\n",
        "120    AnnArbor-MI_2015-1H_Sprint_Detail.csv  0.181483953    STA\n",
        "13      StLouis-MO_2015-1H_Sprint_Detail.csv  0.878378747    STA\n",
        "10        Tampa-FL_2015-1H_Sprint_Detail.csv  0.142036688    STA\n",
        "0    Youngstown-OH_2015-1H_Sprint_Detail.csv  0.271592731    STA\n",
        "124       Akron-OH_2015-1H_Sprint_Detail.csv  0.987746447    STA\n"
       ]
      }
     ],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pandas merge to perform table lookup and join. Let's try on an abbreviate list too."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Using mdf2 which stripped only STA\n",
      "merged_left = pd.merge(left=test_df,right=mdf2, how='left', left_on='Sprint', right_on='Sprint')\n",
      "\n",
      "merged_left.sort(columns='Vendor', ascending='True', inplace='True')\n",
      "print merged_left.head(5)\n",
      "print merged_left.tail(5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                                     Sprint         Data Vendor\n",
        "0   Youngstown-OH_2015-1H_Sprint_Detail.csv  0.271592731    STA\n",
        "10       Tampa-FL_2015-1H_Sprint_Detail.csv  0.142036688    STA\n",
        "13     StLouis-MO_2015-1H_Sprint_Detail.csv  0.878378747    STA\n",
        "16  Shreveport-LA_2015-1H_Sprint_Detail.csv  0.884742004    STA\n",
        "18    Scranton-PA_2015-1H_Sprint_Detail.csv  0.614807618    STA\n",
        "                                       Sprint         Data Vendor\n",
        "118      Augusta-GA_2015-1H_Sprint_Detail.csv  0.401477427    NaN\n",
        "119      Atlanta-GA_2015-1H_Sprint_Detail.csv  0.696953405    NaN\n",
        "121    Allentown-PA_2015-1H_Sprint_Detail.csv  0.579945705    NaN\n",
        "122  Albuquerque-NM_2015-1H_Sprint_Detail.csv  0.355644658    NaN\n",
        "123       Albany-NY_2015-1H_Sprint_Detail.csv  0.116642419    NaN\n"
       ]
      }
     ],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grab Basestations seen in failed tests\n",
      "fail_count = df[['Base_Station_ID']].groupby([df['Base_Station_ID']]).agg(len)\n",
      "idx = fail_count.index.tolist()\n",
      "print df['Collection'][0]\n",
      "_metro_map ={}\n",
      "_metro_map['RmMetro'] = df['Collection'][0]\n",
      "_metro_map['cellid'] = idx\n",
      "# print _metro_map\n",
      "_stat = {}\n",
      "_stat = dict(zip(idx,fail_count['Base_Station_ID'].values))\n",
      "x = _stat\n",
      "y = _stat\n",
      "_stat = { k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y) }\n",
      "#print '_stat  is the mapping of BS ID to number of times seen in the set', _stat\n",
      "print \"Unique CDMA Base Stations\", len(_stat.keys())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grab Basestations seen in failed tests\n",
      "fail_count = df[['LTE_eNB_ID']].groupby([df['LTE_eNB_ID']]).agg(len)\n",
      "idx = fail_count.index.tolist()\n",
      "print df['Collection'][0]\n",
      "_metro_map ={}\n",
      "_metro_map['RmMetro'] = df['Collection'][0]\n",
      "_metro_map['eNB_ID'] = idx\n",
      "# print _metro_map\n",
      "_stat = {}\n",
      "_stat = dict(zip(idx,fail_count['LTE_eNB_ID'].values))\n",
      "x = _stat\n",
      "y = _stat\n",
      "_stat = { k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y) }\n",
      "del x\n",
      "del y\n",
      "y = _stat\n",
      "y=sorted(y.items(), key=lambda x: (x[1],x[0]), reverse=True)\n",
      "#print '_stat  is the mapping of BS ID to number of times seen in the set', y\n",
      "print 'Unique eNB IDs ', len(_stat.keys())\n",
      "print int(len(_stat.keys()))\n",
      " \n",
      "dummy, enbid_count = get_stats.get_enbid_count(df)\n",
      "print enbid_count"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Grab Basestations seen in failed tests\n",
      "fail_count = df[['Network_MCC','Network_MNC']].groupby([df['Network_MCC'],df['Network_MNC']]).agg(len)\n",
      "idx = fail_count.index.tolist()\n",
      "print df['Collection'][0]\n",
      "_metro_map ={}\n",
      "_metro_map['RmMetro'] = df['Collection'][0]\n",
      "_metro_map['mcc'] = idx\n",
      "# print _metro_map\n",
      "_stat = {}\n",
      "_stat = dict(zip(idx,fail_count['Network_MCC'].values))\n",
      "x = _stat\n",
      "y = _stat\n",
      "_stat = { k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y) }\n",
      "#print '_stat  is the mapping of BS ID to number of times seen in the set', _stat\n",
      "print len(_stat.keys())\n",
      "print df['Collection'][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "import calc_distance\n",
      "\n",
      "lat_total = df['Garmin_Latitude'].dropna(sbset=['Garmin_Longitude'], how ='any', inplace =0).values\n",
      "long_total = df['Garmin_Longitude'].dropna(sbset=['Garmin_Longitude'], how ='any', inplace =0).values\n",
      " \n",
      "left_top = (long_total.min(), lat_total.max())\n",
      "left_bottom = (long_total.min(), lat_total.min())\n",
      "right_top = (long_total.max(), lat_total.max())\n",
      "right_bottom = (long_total.max(), lat_total.max())\n",
      "\n",
      "right_top = (float(lat_total.max()), float(long_total.min()) )\n",
      "right_bottom = (float(lat_total.min()), float(long_total.min()))\n",
      "left_top = (float(lat_total.max()), float(long_total.max()))\n",
      "left_bottom = (float(lat_total.min()), float(long_total.max()))\n",
      "\n",
      "print len(lat_total), left_top, left_bottom\n",
      "print right_top, right_bottom\n",
      "# Distance\n",
      "dimA = calc_distance.get_dist_to_cell(left_bottom[0],left_bottom[1],left_top[0],left_top[1])\n",
      "dimB = calc_distance.get_dist_to_cell(left_bottom[0],left_bottom[1],right_bottom[0],right_bottom[1])\n",
      "area = dimA*dimB\n",
      "area = np.sqrt(area)\n",
      "box = (left_bottom, left_top, right_bottom, right_top)\n",
      "print dimA, dimB, dimA*dimB, enbid_count/area\n",
      "print type(box), len(box) , box[3][0]\n",
      "print box"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "box, area = calc_distance.get_box(df)\n",
      "print 'Box ', box, 'Area %2.0f Sq meters'%area"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type_flag ='FAILED'\n",
      "stat_name = 'LTE_RSRP'\n",
      "nfi, failed_stats2, dm_fail = get_stats.get_lte_fail_stats(df.copy(), type_flag,stat_name)\n",
      "stat_name = 'CDMA_Signal_Strength'                    \n",
      "nfi, failed_stats, dm_call, call_duration = get_stats.get_ss_stats(df.copy(), stat_name)\n",
      " "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "#Downlink_Throughput:Network_Types\n",
      "#Uplink_Throughput:Network_Types\n",
      "# Downlink_Throughput:Traffic\n",
      "\n",
      "type_flag ='FAILED'\n",
      "stat_name = 'Downlink_Throughput:Final_Test_Speed'\n",
      "\n",
      "time_took, all_stat_dltput = get_stats.get_gen_stat(df.copy(),stat_name)\n",
      "print stat_name,  '  Mean, Max, Min, Std, Median', all_stat_dltput\n",
      "\n",
      "\n",
      "stat_name = 'Uplink_Throughput:Final_Test_Speed'\n",
      "\n",
      "time_took, all_stat_ultput = get_stats.get_gen_stat(df.copy(),stat_name)\n",
      "print stat_name,  '  Mean, Max, Min, Std, Median', all_stat_ultput"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if True:\n",
      "    my_type, tp_speed = get_stats.get_tput_count(df,'Downlink_Throughput:Network_Types','Downlink_Throughput:Final_Test_Speed')\n",
      "    tol = float(my_type[0])/my_type[5]\n",
      "    print  '\\nFile ', f, my_type, 'Time on LTE ', tol, '\\nMedian Mixed speed ', tp_speed[5],  '\\nMedian Speed on LTE', tp_speed[1]\n",
      "    print 'Mean mixed speed ', tp_speed\n",
      "    my_type, tp_speed = get_stats.get_tput_count(df,'Uplink_Throughput:Network_Types','Uplink_Throughput:Final_Test_Speed')\n",
      "    tol = float(my_type[0])/my_type[5]\n",
      "    print   '\\nFile ', f,my_type, 'Time on LTE ', tol, '\\nMedian Mixed speed ', tp_speed[5], '\\nMedian Speed on LTE', tp_speed[1]\n",
      "    print 'Mean mixed speed ', tp_speed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import calc_distance as cd\n",
      "from math import isnan\n",
      "\n",
      "dm_fail = dm_fail.convert_objects(convert_numeric=True)\n",
      "clean_bs_dict = cd.create_base_station_dict(dm_fail)\n",
      "avg_dist = cd.get_average_distance(clean_bs_dict,dm_fail)\n",
      "#print 'Average Distance ', avg_dist, 'LTE eNB information? ', clean_bs_dict\n",
      "\n",
      "if False:\n",
      "    bs_coord = zip (df['Base_Station_Latitude'].values,df['Base_Station_Longitude'].values)\n",
      "    bs_dict = dict(zip (df['LTE_eNB_ID'],bs_coord))\n",
      "    #Base_Station_ID  Base_Station_Longitude\n",
      "   \n",
      "    #######################\n",
      "    # Remove NaNs from dictionary\n",
      "    \n",
      "\n",
      "    #clean_bs_dict = dict((k, v) for k, v in bs_dict.items() if not (type(k) == float or isnan(k)))\n",
      "    print bs_dict\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import time\n",
      "\n",
      "# Rather than Change working existing routines.  Create new mod that\n",
      "# will take a data frame and field and compute stats\n",
      "stat_name ='CDMA_Signal_Strength'\n",
      "#stat_name = 'CDMA_Ecio'\n",
      "stat_name ='Downlink_Throughput:Final_Test_Speed'\n",
      "stat_name ='Uplink_Throughput:Final_Test_Speed'\n",
      "\n",
      "if stat_name ==\"\":\n",
      "    print 'No valid stat passed'\n",
      "\n",
      "\n",
      "start = time.time() \n",
      "################################################################\n",
      "################################################################\n",
      "#Remove NA values on RSRP\n",
      "df2 = df.dropna(subset=[stat_name], how ='any', inplace =0)\n",
      "################################################################\n",
      "# Get Stats for Selected Calls\n",
      "\n",
      "call_ss =np.array(df2[stat_name].values)\n",
      "call_ss = call_ss.astype(float)  \n",
      "fail_ss = [call_ss.mean(), call_ss.max(), call_ss.min(), call_ss.std(),np.median(call_ss)]\n",
      "end = time.time()\n",
      "print stat_name, fail_ss\n",
      "# Histogram the number of times on technology\n",
      "#print np.median(call_ss), np.histogram(call_ss, bins = 25)\n",
      "import matplotlib as plt\n",
      "\n",
      "print len(df)\n",
      "labels = call_ss.astype(str)\n",
      "plt.pyplot.hist(call_ss, bins=25, label =labels,cumulative=False, log=False, histtype='bar', range=(call_ss.min(),call_ss.max()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test calculating time on technology and speeds DL/UL\n",
      "################################################################\n",
      "if True:\n",
      "    stat_name = 'Downlink_Throughput:Network_Types'\n",
      "    df2 = df.dropna(subset=[stat_name], how ='any', inplace =0)\n",
      "    ################################################################\n",
      "    # df3 = df3.loc[(df3['Call Final Class qualifier'] !='109') & (df3['Call Final Class qualifier'] !='101')]\n",
      "    lte_type  = df2.loc[df2[stat_name] =='LTE']\n",
      "    print \n",
      "    eHRPD_type  = df2.loc[df2[stat_name] =='eHRPD']\n",
      "    revA_type  = df2.loc[df2[stat_name] =='EVDO revision A']\n",
      "    mix_type  = df2.loc[df2[stat_name] =='LTE,eHRPD']\n",
      "    RTT_type  = df2.loc[df2[stat_name] =='1xRTT']\n",
      "    print  'LTE', lte_type[stat_name].count() ,\\\n",
      "        'eHRPD ', eHRPD_type[stat_name].count(),'LTE ', \\\n",
      "        'Mix ',  mix_type[stat_name].count(),'1x RTT ',  RTT_type[stat_name].count(), \\\n",
      "        'Rev A ', revA_type[stat_name].count(), \\\n",
      "        'Total', len(df2)\n",
      "\n",
      "    net_type= (lte_type[stat_name].count(), \\\n",
      "                  eHRPD_type[stat_name].count(), \\\n",
      "                  mix_type[stat_name].count(),\\\n",
      "                  revA_type[stat_name].count(), \\\n",
      "                  RTT_type[stat_name].count(), \\\n",
      "                  len(df2)\n",
      "                  )\n",
      "    print net_type\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Discover information about BS when on eHRPD\n",
      "#Data_Network_Type\n",
      "\n",
      "if False:\n",
      "    stat_name = 'Data_Network_Type'\n",
      "    df2 = df.dropna(subset=[stat_name], how ='any', inplace =0)\n",
      "    eHRPD_type  = df2.loc[df2[stat_name] =='eHRPD']\n",
      "    eHRPD_type.dropna(subset=['Base_Station_ID'], how ='any', inplace =1)\n",
      "    isreal = eHRPD_type['Base_Station_ID'].values\n",
      "    print isreal\n",
      "    \n",
      "########################################################\n",
      "#  The Data Network type field applies more generally to the uplink/downlink network type fields.\n",
      "#  The ul/dl network type data fields are only recorded for the respective test ends which don't include BS\n",
      "stat_name = 'Data_Network_Type'\n",
      "# Recalculate from the original eHRPD metrics but get rid of any that are not recorded\n",
      "###########################\n",
      "df2 = df.dropna(subset=[stat_name], how ='any', inplace =0)\n",
      "eHRPD_type  = df2.loc[df2[stat_name] =='eHRPD']\n",
      "###########################\n",
      "\n",
      "fail_count = eHRPD_type[[stat_name,'Base_Station_ID']].groupby([eHRPD_type[stat_name],\\\n",
      "                eHRPD_type['Base_Station_ID']]).agg(len)\n",
      "idx = fail_count.index.tolist()\n",
      "# This mapping is not useful here, but will be used later\n",
      "_metro_map ={}\n",
      "_metro_map['RmMetro'] = f\n",
      "_metro_map['cellid'] = idx\n",
      "#print 'Metro Map ',_metro_map\n",
      "#print 'idx ', type (idx), idx\n",
      "_stat = {}\n",
      "_stat = dict(zip(idx,fail_count['Base_Station_ID'].values))\n",
      "x = _stat\n",
      "y = _stat\n",
      "_stat = { k: x.get(k, 0) + y.get(k, 0) for k in set(x) | set(y) }\n",
      "print len(eHRPD_type)\n",
      "#print '_stat  is the mapping of BS ID to number of times seen in the set \\n', _stat"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Downlink_Throughput:Traffic\n",
      "stat_name = 'Downlink_Throughput:Final_Test_Speed'\n",
      "lte_type.dropna(subset=[stat_name], how ='any', inplace =1)\n",
      "lte_type_value = np.array(lte_type[stat_name].values, dtype =float)\n",
      "print 'LTE Mean/Median DL Throughput ', lte_type_value.mean(), np.median(lte_type_value)\n",
      "\n",
      "eHRPD_type.dropna(subset=[stat_name], how ='any', inplace =1)\n",
      "eHRPD_type_value = np.array(eHRPD_type[stat_name].values, dtype =float)\n",
      "print 'eHRPD Mean/Median DL Throughput ', eHRPD_type_value.mean(), np.median(eHRPD_type_value)\n",
      " \n",
      "\n",
      "mix_type.dropna(subset=[stat_name], how ='any', inplace =1)\n",
      "mix_type_value = np.array(mix_type[stat_name].values, dtype =float)\n",
      "print 'LTE/eHRPD Mean/Median DL Throughput ', mix_type_value.mean(), np.median(mix_type_value)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Test calculating time on technology and speeds DL/UL\n",
      "################################################################\n",
      "if True:\n",
      "    del df2\n",
      "    stat_name = 'Uplink_Throughput:Network_Types'\n",
      "    df2 = df.dropna(subset=[stat_name], how ='any', inplace =0)\n",
      "    ################################################################\n",
      "    # df3 = df3.loc[(df3['Call Final Class qualifier'] !='109') & (df3['Call Final Class qualifier'] !='101')]\n",
      "    lte_type  = df2.loc[df2[stat_name] =='LTE']\n",
      "    print \n",
      "    eHRPD_type  = df2.loc[df2[stat_name] =='eHRPD']\n",
      "    revA_type  = df2.loc[df2[stat_name] =='EVDO revision A']\n",
      "    mix_type  = df2.loc[df2[stat_name] =='LTE,eHRPD']\n",
      "    RTT_type  = df2.loc[df2[stat_name] =='1xRTT']\n",
      "    print 'LTE ', lte_type[stat_name].count() , 'eHRPD ', eHRPD_type[stat_name].count(),\\\n",
      "       'Mix ',  mix_type[stat_name].count(),'1x RTT ',  RTT_type[stat_name].count(), \\\n",
      "        'Rev A ', revA_type[stat_name].count(), 'Total', len(df2)\n",
      "\n",
      "    net_type= (lte_type[stat_name].count(), \\\n",
      "                  eHRPD_type[stat_name].count(), \\\n",
      "                  mix_type[stat_name].count(),\\\n",
      "                  revA_type[stat_name].count(), \\\n",
      "                  RTT_type[stat_name].count(), \\\n",
      "                  len(df2)\n",
      "                  )\n",
      "    print net_type"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Uplink_Throughput:Traffic\n",
      "stat_name = 'Uplink_Throughput:Final_Test_Speed'\n",
      "lte_type.dropna(subset=[stat_name], how ='any', inplace =1)\n",
      "lte_type_value = np.array(lte_type[stat_name].values, dtype =float)\n",
      "print 'LTE Mean/Median UL Throughput ',lte_type_value.mean(), np.median(lte_type_value)\n",
      "\n",
      "eHRPD_type.dropna(subset=[stat_name], how ='any', inplace =1)\n",
      "eHRPD_type_value = np.array(eHRPD_type[stat_name].values, dtype =float)\n",
      "print 'eHRPD Mean/Median UL Throughput ',eHRPD_type_value.mean(), np.median(eHRPD_type_value)\n",
      " \n",
      "\n",
      "mix_type.dropna(subset=[stat_name], how ='any', inplace =1)\n",
      "mix_type_value = np.array(mix_type[stat_name].values, dtype =float)\n",
      "print 'LTE/eHRPD Mean/Median UL Throughput ',mix_type_value.mean(), np.median(mix_type_value)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Code Fragment to write a dictionary _stat_list to file\n",
      "import csv\n",
      "csv_file ='../drive-report/file-list.csv'\n",
      "csv_columns = ['RMmetro']\n",
      "try:\n",
      "    with open(csv_file, 'wb') as csvfile:\n",
      "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns,dialect='excel')\n",
      "        writer.writeheader()\n",
      "        for data in stat_list:\n",
      "           writer.writerow(data)\n",
      "except IOError as (errno, strerror):\n",
      "        print(\"I/O error({0}): {1}\".format(errno, strerror))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}